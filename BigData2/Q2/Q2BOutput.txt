        at org.apache.spark.repl.Main$.main(Main.scala:31)
        at org.apache.spark.repl.Main.main(Main.scala)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:606)
        at org.apache.spark.deploy.SparkSubmit$.launch(SparkSubmit.scala:358)
        at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:75)
        at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
15/10/17 18:42:23 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/stages/stage/kill,null}
15/10/17 18:42:23 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/,null}
15/10/17 18:42:23 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/static,null}
15/10/17 18:42:23 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/executors/threadDump/json,null}
15/10/17 18:42:23 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/executors/threadDump,null}
15/10/17 18:42:23 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/executors/json,null}
15/10/17 18:42:23 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/executors,null}
15/10/17 18:42:23 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/environment/json,null}
15/10/17 18:42:23 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/environment,null}
15/10/17 18:42:23 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/storage/rdd/json,null}
15/10/17 18:42:23 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/storage/rdd,null}
15/10/17 18:42:23 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/storage/json,null}
15/10/17 18:42:23 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/storage,null}
15/10/17 18:42:23 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/stages/pool/json,null}
15/10/17 18:42:23 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/stages/pool,null}
15/10/17 18:42:23 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/stages/stage/json,null}
15/10/17 18:42:23 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/stages/stage,null}
15/10/17 18:42:23 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/stages/json,null}
15/10/17 18:42:23 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/stages,null}
15/10/17 18:42:23 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/jobs/job/json,null}
15/10/17 18:42:23 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/jobs/job,null}
15/10/17 18:42:23 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/jobs/json,null}
15/10/17 18:42:23 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/jobs,null}
15/10/17 18:42:23 WARN util.Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.
15/10/17 18:42:23 INFO server.Server: jetty-8.y.z-SNAPSHOT
15/10/17 18:42:23 WARN component.AbstractLifeCycle: FAILED SelectChannelConnector@0.0.0.0:4042: java.net.BindException: Address already in use
java.net.BindException: Address already in use
        at sun.nio.ch.Net.bind0(Native Method)
        at sun.nio.ch.Net.bind(Net.java:444)
        at sun.nio.ch.Net.bind(Net.java:436)
        at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:214)
        at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
        at org.eclipse.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
        at org.eclipse.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
        at org.eclipse.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
        at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
        at org.eclipse.jetty.server.Server.doStart(Server.java:293)
        at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
        at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:194)
        at org.apache.spark.ui.JettyUtils$$anonfun$2.apply(JettyUtils.scala:204)
        at org.apache.spark.ui.JettyUtils$$anonfun$2.apply(JettyUtils.scala:204)
        at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1676)
        at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
        at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1667)
        at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:204)
        at org.apache.spark.ui.WebUI.bind(WebUI.scala:102)
        at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:269)
        at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:269)
        at scala.Option.foreach(Option.scala:236)
        at org.apache.spark.SparkContext.<init>(SparkContext.scala:269)
        at org.apache.spark.repl.SparkILoop.createSparkContext(SparkILoop.scala:986)
        at $line3.$read$$iwC$$iwC.<init>(<console>:9)
        at $line3.$read$$iwC.<init>(<console>:18)
        at $line3.$read.<init>(<console>:20)
        at $line3.$read$.<init>(<console>:24)
        at $line3.$read$.<clinit>(<console>)
        at $line3.$eval$.<init>(<console>:7)
        at $line3.$eval$.<clinit>(<console>)
        at $line3.$eval.$print(<console>)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:606)
        at org.apache.spark.repl.SparkIMain$ReadEvalPrint.call(SparkIMain.scala:852)
        at org.apache.spark.repl.SparkIMain$Request.loadAndRun(SparkIMain.scala:1125)
        at org.apache.spark.repl.SparkIMain.loadAndRunReq$1(SparkIMain.scala:674)
        at org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:705)
        at org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:669)
        at org.apache.spark.repl.SparkILoop.reallyInterpret$1(SparkILoop.scala:828)
        at org.apache.spark.repl.SparkILoop.interpretStartingWith(SparkILoop.scala:873)
        at org.apache.spark.repl.SparkILoop.command(SparkILoop.scala:785)
        at org.apache.spark.repl.SparkILoopInit$$anonfun$initializeSpark$1.apply(SparkILoopInit.scala:123)
        at org.apache.spark.repl.SparkILoopInit$$anonfun$initializeSpark$1.apply(SparkILoopInit.scala:122)
        at org.apache.spark.repl.SparkIMain.beQuietDuring(SparkIMain.scala:270)
        at org.apache.spark.repl.SparkILoopInit$class.initializeSpark(SparkILoopInit.scala:122)
        at org.apache.spark.repl.SparkILoop.initializeSpark(SparkILoop.scala:60)
        at org.apache.spark.repl.SparkILoop$$anonfun$process$1$$anonfun$apply$mcZ$sp$5.apply$mcV$sp(SparkILoop.scala:945)
        at org.apache.spark.repl.SparkILoopInit$class.runThunks(SparkILoopInit.scala:147)
        at org.apache.spark.repl.SparkILoop.runThunks(SparkILoop.scala:60)
        at org.apache.spark.repl.SparkILoopInit$class.postInitialization(SparkILoopInit.scala:106)
        at org.apache.spark.repl.SparkILoop.postInitialization(SparkILoop.scala:60)
        at org.apache.spark.repl.SparkILoop$$anonfun$process$1.apply$mcZ$sp(SparkILoop.scala:962)
        at org.apache.spark.repl.SparkILoop$$anonfun$process$1.apply(SparkILoop.scala:916)
        at org.apache.spark.repl.SparkILoop$$anonfun$process$1.apply(SparkILoop.scala:916)
        at scala.tools.nsc.util.ScalaClassLoader$.savingContextLoader(ScalaClassLoader.scala:135)
        at org.apache.spark.repl.SparkILoop.process(SparkILoop.scala:916)
        at org.apache.spark.repl.SparkILoop.process(SparkILoop.scala:1011)
        at org.apache.spark.repl.Main$.main(Main.scala:31)
        at org.apache.spark.repl.Main.main(Main.scala)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:606)
        at org.apache.spark.deploy.SparkSubmit$.launch(SparkSubmit.scala:358)
        at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:75)
        at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
15/10/17 18:42:23 WARN component.AbstractLifeCycle: FAILED org.eclipse.jetty.server.Server@427d5327: java.net.BindException: Address already in use
java.net.BindException: Address already in use
        at sun.nio.ch.Net.bind0(Native Method)
        at sun.nio.ch.Net.bind(Net.java:444)
        at sun.nio.ch.Net.bind(Net.java:436)
        at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:214)
        at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
        at org.eclipse.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
        at org.eclipse.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
        at org.eclipse.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
        at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
        at org.eclipse.jetty.server.Server.doStart(Server.java:293)
        at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
        at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:194)
        at org.apache.spark.ui.JettyUtils$$anonfun$2.apply(JettyUtils.scala:204)
        at org.apache.spark.ui.JettyUtils$$anonfun$2.apply(JettyUtils.scala:204)
        at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1676)
        at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
        at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1667)
        at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:204)
        at org.apache.spark.ui.WebUI.bind(WebUI.scala:102)
        at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:269)
        at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:269)
        at scala.Option.foreach(Option.scala:236)
        at org.apache.spark.SparkContext.<init>(SparkContext.scala:269)
        at org.apache.spark.repl.SparkILoop.createSparkContext(SparkILoop.scala:986)
        at $line3.$read$$iwC$$iwC.<init>(<console>:9)
        at $line3.$read$$iwC.<init>(<console>:18)
        at $line3.$read.<init>(<console>:20)
        at $line3.$read$.<init>(<console>:24)
        at $line3.$read$.<clinit>(<console>)
        at $line3.$eval$.<init>(<console>:7)
        at $line3.$eval$.<clinit>(<console>)
        at $line3.$eval.$print(<console>)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:606)
        at org.apache.spark.repl.SparkIMain$ReadEvalPrint.call(SparkIMain.scala:852)
        at org.apache.spark.repl.SparkIMain$Request.loadAndRun(SparkIMain.scala:1125)
        at org.apache.spark.repl.SparkIMain.loadAndRunReq$1(SparkIMain.scala:674)
        at org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:705)
        at org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:669)
        at org.apache.spark.repl.SparkILoop.reallyInterpret$1(SparkILoop.scala:828)
        at org.apache.spark.repl.SparkILoop.interpretStartingWith(SparkILoop.scala:873)
        at org.apache.spark.repl.SparkILoop.command(SparkILoop.scala:785)
        at org.apache.spark.repl.SparkILoopInit$$anonfun$initializeSpark$1.apply(SparkILoopInit.scala:123)
        at org.apache.spark.repl.SparkILoopInit$$anonfun$initializeSpark$1.apply(SparkILoopInit.scala:122)
        at org.apache.spark.repl.SparkIMain.beQuietDuring(SparkIMain.scala:270)
        at org.apache.spark.repl.SparkILoopInit$class.initializeSpark(SparkILoopInit.scala:122)
        at org.apache.spark.repl.SparkILoop.initializeSpark(SparkILoop.scala:60)
        at org.apache.spark.repl.SparkILoop$$anonfun$process$1$$anonfun$apply$mcZ$sp$5.apply$mcV$sp(SparkILoop.scala:945)
        at org.apache.spark.repl.SparkILoopInit$class.runThunks(SparkILoopInit.scala:147)
        at org.apache.spark.repl.SparkILoop.runThunks(SparkILoop.scala:60)
        at org.apache.spark.repl.SparkILoopInit$class.postInitialization(SparkILoopInit.scala:106)
        at org.apache.spark.repl.SparkILoop.postInitialization(SparkILoop.scala:60)
        at org.apache.spark.repl.SparkILoop$$anonfun$process$1.apply$mcZ$sp(SparkILoop.scala:962)
        at org.apache.spark.repl.SparkILoop$$anonfun$process$1.apply(SparkILoop.scala:916)
        at org.apache.spark.repl.SparkILoop$$anonfun$process$1.apply(SparkILoop.scala:916)
        at scala.tools.nsc.util.ScalaClassLoader$.savingContextLoader(ScalaClassLoader.scala:135)
        at org.apache.spark.repl.SparkILoop.process(SparkILoop.scala:916)
        at org.apache.spark.repl.SparkILoop.process(SparkILoop.scala:1011)
        at org.apache.spark.repl.Main$.main(Main.scala:31)
        at org.apache.spark.repl.Main.main(Main.scala)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:606)
        at org.apache.spark.deploy.SparkSubmit$.launch(SparkSubmit.scala:358)
        at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:75)
        at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
15/10/17 18:42:23 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/stages/stage/kill,null}
15/10/17 18:42:23 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/,null}
15/10/17 18:42:23 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/static,null}
15/10/17 18:42:23 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/executors/threadDump/json,null}
15/10/17 18:42:23 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/executors/threadDump,null}
15/10/17 18:42:23 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/executors/json,null}
15/10/17 18:42:23 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/executors,null}
15/10/17 18:42:23 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/environment/json,null}
15/10/17 18:42:23 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/environment,null}
15/10/17 18:42:23 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/storage/rdd/json,null}
15/10/17 18:42:23 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/storage/rdd,null}
15/10/17 18:42:23 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/storage/json,null}
15/10/17 18:42:23 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/storage,null}
15/10/17 18:42:23 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/stages/pool/json,null}
15/10/17 18:42:23 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/stages/pool,null}
15/10/17 18:42:23 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/stages/stage/json,null}
15/10/17 18:42:23 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/stages/stage,null}
15/10/17 18:42:23 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/stages/json,null}
15/10/17 18:42:23 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/stages,null}
15/10/17 18:42:23 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/jobs/job/json,null}
15/10/17 18:42:23 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/jobs/job,null}
15/10/17 18:42:23 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/jobs/json,null}
15/10/17 18:42:23 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/jobs,null}
15/10/17 18:42:23 WARN util.Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.
15/10/17 18:42:23 INFO server.Server: jetty-8.y.z-SNAPSHOT
15/10/17 18:42:23 WARN component.AbstractLifeCycle: FAILED SelectChannelConnector@0.0.0.0:4043: java.net.BindException: Address already in use
java.net.BindException: Address already in use
        at sun.nio.ch.Net.bind0(Native Method)
        at sun.nio.ch.Net.bind(Net.java:444)
        at sun.nio.ch.Net.bind(Net.java:436)
        at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:214)
        at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
        at org.eclipse.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
        at org.eclipse.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
        at org.eclipse.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
        at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
        at org.eclipse.jetty.server.Server.doStart(Server.java:293)
        at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
        at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:194)
        at org.apache.spark.ui.JettyUtils$$anonfun$2.apply(JettyUtils.scala:204)
        at org.apache.spark.ui.JettyUtils$$anonfun$2.apply(JettyUtils.scala:204)
        at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1676)
        at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
        at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1667)
        at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:204)
        at org.apache.spark.ui.WebUI.bind(WebUI.scala:102)
        at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:269)
        at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:269)
        at scala.Option.foreach(Option.scala:236)
        at org.apache.spark.SparkContext.<init>(SparkContext.scala:269)
        at org.apache.spark.repl.SparkILoop.createSparkContext(SparkILoop.scala:986)
        at $line3.$read$$iwC$$iwC.<init>(<console>:9)
        at $line3.$read$$iwC.<init>(<console>:18)
        at $line3.$read.<init>(<console>:20)
        at $line3.$read$.<init>(<console>:24)
        at $line3.$read$.<clinit>(<console>)
        at $line3.$eval$.<init>(<console>:7)
        at $line3.$eval$.<clinit>(<console>)
        at $line3.$eval.$print(<console>)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:606)
        at org.apache.spark.repl.SparkIMain$ReadEvalPrint.call(SparkIMain.scala:852)
        at org.apache.spark.repl.SparkIMain$Request.loadAndRun(SparkIMain.scala:1125)
        at org.apache.spark.repl.SparkIMain.loadAndRunReq$1(SparkIMain.scala:674)
        at org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:705)
        at org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:669)
        at org.apache.spark.repl.SparkILoop.reallyInterpret$1(SparkILoop.scala:828)
        at org.apache.spark.repl.SparkILoop.interpretStartingWith(SparkILoop.scala:873)
        at org.apache.spark.repl.SparkILoop.command(SparkILoop.scala:785)
        at org.apache.spark.repl.SparkILoopInit$$anonfun$initializeSpark$1.apply(SparkILoopInit.scala:123)
        at org.apache.spark.repl.SparkILoopInit$$anonfun$initializeSpark$1.apply(SparkILoopInit.scala:122)
        at org.apache.spark.repl.SparkIMain.beQuietDuring(SparkIMain.scala:270)
        at org.apache.spark.repl.SparkILoopInit$class.initializeSpark(SparkILoopInit.scala:122)
        at org.apache.spark.repl.SparkILoop.initializeSpark(SparkILoop.scala:60)
        at org.apache.spark.repl.SparkILoop$$anonfun$process$1$$anonfun$apply$mcZ$sp$5.apply$mcV$sp(SparkILoop.scala:945)
        at org.apache.spark.repl.SparkILoopInit$class.runThunks(SparkILoopInit.scala:147)
        at org.apache.spark.repl.SparkILoop.runThunks(SparkILoop.scala:60)
        at org.apache.spark.repl.SparkILoopInit$class.postInitialization(SparkILoopInit.scala:106)
        at org.apache.spark.repl.SparkILoop.postInitialization(SparkILoop.scala:60)
        at org.apache.spark.repl.SparkILoop$$anonfun$process$1.apply$mcZ$sp(SparkILoop.scala:962)
        at org.apache.spark.repl.SparkILoop$$anonfun$process$1.apply(SparkILoop.scala:916)
        at org.apache.spark.repl.SparkILoop$$anonfun$process$1.apply(SparkILoop.scala:916)
        at scala.tools.nsc.util.ScalaClassLoader$.savingContextLoader(ScalaClassLoader.scala:135)
        at org.apache.spark.repl.SparkILoop.process(SparkILoop.scala:916)
        at org.apache.spark.repl.SparkILoop.process(SparkILoop.scala:1011)
        at org.apache.spark.repl.Main$.main(Main.scala:31)
        at org.apache.spark.repl.Main.main(Main.scala)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:606)
        at org.apache.spark.deploy.SparkSubmit$.launch(SparkSubmit.scala:358)
        at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:75)
        at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
15/10/17 18:42:23 WARN component.AbstractLifeCycle: FAILED org.eclipse.jetty.server.Server@6c25c783: java.net.BindException: Address already in use
java.net.BindException: Address already in use
        at sun.nio.ch.Net.bind0(Native Method)
        at sun.nio.ch.Net.bind(Net.java:444)
        at sun.nio.ch.Net.bind(Net.java:436)
        at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:214)
        at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
        at org.eclipse.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
        at org.eclipse.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
        at org.eclipse.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
        at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
        at org.eclipse.jetty.server.Server.doStart(Server.java:293)
        at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
        at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:194)
        at org.apache.spark.ui.JettyUtils$$anonfun$2.apply(JettyUtils.scala:204)
        at org.apache.spark.ui.JettyUtils$$anonfun$2.apply(JettyUtils.scala:204)
        at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1676)
        at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
        at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1667)
        at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:204)
        at org.apache.spark.ui.WebUI.bind(WebUI.scala:102)
        at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:269)
        at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:269)
        at scala.Option.foreach(Option.scala:236)
        at org.apache.spark.SparkContext.<init>(SparkContext.scala:269)
        at org.apache.spark.repl.SparkILoop.createSparkContext(SparkILoop.scala:986)
        at $line3.$read$$iwC$$iwC.<init>(<console>:9)
        at $line3.$read$$iwC.<init>(<console>:18)
        at $line3.$read.<init>(<console>:20)
        at $line3.$read$.<init>(<console>:24)
        at $line3.$read$.<clinit>(<console>)
        at $line3.$eval$.<init>(<console>:7)
        at $line3.$eval$.<clinit>(<console>)
        at $line3.$eval.$print(<console>)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:606)
        at org.apache.spark.repl.SparkIMain$ReadEvalPrint.call(SparkIMain.scala:852)
        at org.apache.spark.repl.SparkIMain$Request.loadAndRun(SparkIMain.scala:1125)
        at org.apache.spark.repl.SparkIMain.loadAndRunReq$1(SparkIMain.scala:674)
        at org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:705)
        at org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:669)
        at org.apache.spark.repl.SparkILoop.reallyInterpret$1(SparkILoop.scala:828)
        at org.apache.spark.repl.SparkILoop.interpretStartingWith(SparkILoop.scala:873)
        at org.apache.spark.repl.SparkILoop.command(SparkILoop.scala:785)
        at org.apache.spark.repl.SparkILoopInit$$anonfun$initializeSpark$1.apply(SparkILoopInit.scala:123)
        at org.apache.spark.repl.SparkILoopInit$$anonfun$initializeSpark$1.apply(SparkILoopInit.scala:122)
        at org.apache.spark.repl.SparkIMain.beQuietDuring(SparkIMain.scala:270)
        at org.apache.spark.repl.SparkILoopInit$class.initializeSpark(SparkILoopInit.scala:122)
        at org.apache.spark.repl.SparkILoop.initializeSpark(SparkILoop.scala:60)
        at org.apache.spark.repl.SparkILoop$$anonfun$process$1$$anonfun$apply$mcZ$sp$5.apply$mcV$sp(SparkILoop.scala:945)
        at org.apache.spark.repl.SparkILoopInit$class.runThunks(SparkILoopInit.scala:147)
        at org.apache.spark.repl.SparkILoop.runThunks(SparkILoop.scala:60)
        at org.apache.spark.repl.SparkILoopInit$class.postInitialization(SparkILoopInit.scala:106)
        at org.apache.spark.repl.SparkILoop.postInitialization(SparkILoop.scala:60)
        at org.apache.spark.repl.SparkILoop$$anonfun$process$1.apply$mcZ$sp(SparkILoop.scala:962)
        at org.apache.spark.repl.SparkILoop$$anonfun$process$1.apply(SparkILoop.scala:916)
        at org.apache.spark.repl.SparkILoop$$anonfun$process$1.apply(SparkILoop.scala:916)
        at scala.tools.nsc.util.ScalaClassLoader$.savingContextLoader(ScalaClassLoader.scala:135)
        at org.apache.spark.repl.SparkILoop.process(SparkILoop.scala:916)
        at org.apache.spark.repl.SparkILoop.process(SparkILoop.scala:1011)
        at org.apache.spark.repl.Main$.main(Main.scala:31)
        at org.apache.spark.repl.Main.main(Main.scala)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:606)
        at org.apache.spark.deploy.SparkSubmit$.launch(SparkSubmit.scala:358)
        at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:75)
        at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
15/10/17 18:42:23 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/stages/stage/kill,null}
15/10/17 18:42:23 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/,null}
15/10/17 18:42:23 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/static,null}
15/10/17 18:42:23 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/executors/threadDump/json,null}
15/10/17 18:42:23 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/executors/threadDump,null}
15/10/17 18:42:23 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/executors/json,null}
15/10/17 18:42:23 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/executors,null}
15/10/17 18:42:23 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/environment/json,null}
15/10/17 18:42:23 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/environment,null}
15/10/17 18:42:23 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/storage/rdd/json,null}
15/10/17 18:42:23 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/storage/rdd,null}
15/10/17 18:42:23 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/storage/json,null}
15/10/17 18:42:23 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/storage,null}
15/10/17 18:42:23 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/stages/pool/json,null}
15/10/17 18:42:23 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/stages/pool,null}
15/10/17 18:42:23 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/stages/stage/json,null}
15/10/17 18:42:23 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/stages/stage,null}
15/10/17 18:42:23 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/stages/json,null}
15/10/17 18:42:23 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/stages,null}
15/10/17 18:42:23 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/jobs/job/json,null}
15/10/17 18:42:23 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/jobs/job,null}
15/10/17 18:42:23 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/jobs/json,null}
15/10/17 18:42:23 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/jobs,null}
15/10/17 18:42:23 WARN util.Utils: Service 'SparkUI' could not bind on port 4043. Attempting port 4044.
15/10/17 18:42:23 INFO server.Server: jetty-8.y.z-SNAPSHOT
15/10/17 18:42:23 WARN component.AbstractLifeCycle: FAILED SelectChannelConnector@0.0.0.0:4044: java.net.BindException: Address already in use
java.net.BindException: Address already in use
        at sun.nio.ch.Net.bind0(Native Method)
        at sun.nio.ch.Net.bind(Net.java:444)
        at sun.nio.ch.Net.bind(Net.java:436)
        at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:214)
        at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
        at org.eclipse.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
        at org.eclipse.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
        at org.eclipse.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
        at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
        at org.eclipse.jetty.server.Server.doStart(Server.java:293)
        at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
        at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:194)
        at org.apache.spark.ui.JettyUtils$$anonfun$2.apply(JettyUtils.scala:204)
        at org.apache.spark.ui.JettyUtils$$anonfun$2.apply(JettyUtils.scala:204)
        at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1676)
        at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
        at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1667)
        at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:204)
        at org.apache.spark.ui.WebUI.bind(WebUI.scala:102)
        at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:269)
        at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:269)
        at scala.Option.foreach(Option.scala:236)
        at org.apache.spark.SparkContext.<init>(SparkContext.scala:269)
        at org.apache.spark.repl.SparkILoop.createSparkContext(SparkILoop.scala:986)
        at $line3.$read$$iwC$$iwC.<init>(<console>:9)
        at $line3.$read$$iwC.<init>(<console>:18)
        at $line3.$read.<init>(<console>:20)
        at $line3.$read$.<init>(<console>:24)
        at $line3.$read$.<clinit>(<console>)
        at $line3.$eval$.<init>(<console>:7)
        at $line3.$eval$.<clinit>(<console>)
        at $line3.$eval.$print(<console>)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:606)
        at org.apache.spark.repl.SparkIMain$ReadEvalPrint.call(SparkIMain.scala:852)
        at org.apache.spark.repl.SparkIMain$Request.loadAndRun(SparkIMain.scala:1125)
        at org.apache.spark.repl.SparkIMain.loadAndRunReq$1(SparkIMain.scala:674)
        at org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:705)
        at org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:669)
        at org.apache.spark.repl.SparkILoop.reallyInterpret$1(SparkILoop.scala:828)
        at org.apache.spark.repl.SparkILoop.interpretStartingWith(SparkILoop.scala:873)
        at org.apache.spark.repl.SparkILoop.command(SparkILoop.scala:785)
        at org.apache.spark.repl.SparkILoopInit$$anonfun$initializeSpark$1.apply(SparkILoopInit.scala:123)
        at org.apache.spark.repl.SparkILoopInit$$anonfun$initializeSpark$1.apply(SparkILoopInit.scala:122)
        at org.apache.spark.repl.SparkIMain.beQuietDuring(SparkIMain.scala:270)
        at org.apache.spark.repl.SparkILoopInit$class.initializeSpark(SparkILoopInit.scala:122)
        at org.apache.spark.repl.SparkILoop.initializeSpark(SparkILoop.scala:60)
        at org.apache.spark.repl.SparkILoop$$anonfun$process$1$$anonfun$apply$mcZ$sp$5.apply$mcV$sp(SparkILoop.scala:945)
        at org.apache.spark.repl.SparkILoopInit$class.runThunks(SparkILoopInit.scala:147)
        at org.apache.spark.repl.SparkILoop.runThunks(SparkILoop.scala:60)
        at org.apache.spark.repl.SparkILoopInit$class.postInitialization(SparkILoopInit.scala:106)
        at org.apache.spark.repl.SparkILoop.postInitialization(SparkILoop.scala:60)
        at org.apache.spark.repl.SparkILoop$$anonfun$process$1.apply$mcZ$sp(SparkILoop.scala:962)
        at org.apache.spark.repl.SparkILoop$$anonfun$process$1.apply(SparkILoop.scala:916)
        at org.apache.spark.repl.SparkILoop$$anonfun$process$1.apply(SparkILoop.scala:916)
        at scala.tools.nsc.util.ScalaClassLoader$.savingContextLoader(ScalaClassLoader.scala:135)
        at org.apache.spark.repl.SparkILoop.process(SparkILoop.scala:916)
        at org.apache.spark.repl.SparkILoop.process(SparkILoop.scala:1011)
        at org.apache.spark.repl.Main$.main(Main.scala:31)
        at org.apache.spark.repl.Main.main(Main.scala)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:606)
        at org.apache.spark.deploy.SparkSubmit$.launch(SparkSubmit.scala:358)
        at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:75)
        at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
15/10/17 18:42:23 WARN component.AbstractLifeCycle: FAILED org.eclipse.jetty.server.Server@c54c0ae: java.net.BindException: Address already in use
java.net.BindException: Address already in use
        at sun.nio.ch.Net.bind0(Native Method)
        at sun.nio.ch.Net.bind(Net.java:444)
        at sun.nio.ch.Net.bind(Net.java:436)
        at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:214)
        at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
        at org.eclipse.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
        at org.eclipse.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
        at org.eclipse.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
        at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
        at org.eclipse.jetty.server.Server.doStart(Server.java:293)
        at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
        at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:194)
        at org.apache.spark.ui.JettyUtils$$anonfun$2.apply(JettyUtils.scala:204)
        at org.apache.spark.ui.JettyUtils$$anonfun$2.apply(JettyUtils.scala:204)
        at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1676)
        at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
        at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1667)
        at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:204)
        at org.apache.spark.ui.WebUI.bind(WebUI.scala:102)
        at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:269)
        at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:269)
        at scala.Option.foreach(Option.scala:236)
        at org.apache.spark.SparkContext.<init>(SparkContext.scala:269)
        at org.apache.spark.repl.SparkILoop.createSparkContext(SparkILoop.scala:986)
        at $line3.$read$$iwC$$iwC.<init>(<console>:9)
        at $line3.$read$$iwC.<init>(<console>:18)
        at $line3.$read.<init>(<console>:20)
        at $line3.$read$.<init>(<console>:24)
        at $line3.$read$.<clinit>(<console>)
        at $line3.$eval$.<init>(<console>:7)
        at $line3.$eval$.<clinit>(<console>)
        at $line3.$eval.$print(<console>)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:606)
        at org.apache.spark.repl.SparkIMain$ReadEvalPrint.call(SparkIMain.scala:852)
        at org.apache.spark.repl.SparkIMain$Request.loadAndRun(SparkIMain.scala:1125)
        at org.apache.spark.repl.SparkIMain.loadAndRunReq$1(SparkIMain.scala:674)
        at org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:705)
        at org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:669)
        at org.apache.spark.repl.SparkILoop.reallyInterpret$1(SparkILoop.scala:828)
        at org.apache.spark.repl.SparkILoop.interpretStartingWith(SparkILoop.scala:873)
        at org.apache.spark.repl.SparkILoop.command(SparkILoop.scala:785)
        at org.apache.spark.repl.SparkILoopInit$$anonfun$initializeSpark$1.apply(SparkILoopInit.scala:123)
        at org.apache.spark.repl.SparkILoopInit$$anonfun$initializeSpark$1.apply(SparkILoopInit.scala:122)
        at org.apache.spark.repl.SparkIMain.beQuietDuring(SparkIMain.scala:270)
        at org.apache.spark.repl.SparkILoopInit$class.initializeSpark(SparkILoopInit.scala:122)
        at org.apache.spark.repl.SparkILoop.initializeSpark(SparkILoop.scala:60)
        at org.apache.spark.repl.SparkILoop$$anonfun$process$1$$anonfun$apply$mcZ$sp$5.apply$mcV$sp(SparkILoop.scala:945)
        at org.apache.spark.repl.SparkILoopInit$class.runThunks(SparkILoopInit.scala:147)
        at org.apache.spark.repl.SparkILoop.runThunks(SparkILoop.scala:60)
        at org.apache.spark.repl.SparkILoopInit$class.postInitialization(SparkILoopInit.scala:106)
        at org.apache.spark.repl.SparkILoop.postInitialization(SparkILoop.scala:60)
        at org.apache.spark.repl.SparkILoop$$anonfun$process$1.apply$mcZ$sp(SparkILoop.scala:962)
        at org.apache.spark.repl.SparkILoop$$anonfun$process$1.apply(SparkILoop.scala:916)
        at org.apache.spark.repl.SparkILoop$$anonfun$process$1.apply(SparkILoop.scala:916)
        at scala.tools.nsc.util.ScalaClassLoader$.savingContextLoader(ScalaClassLoader.scala:135)
        at org.apache.spark.repl.SparkILoop.process(SparkILoop.scala:916)
        at org.apache.spark.repl.SparkILoop.process(SparkILoop.scala:1011)
        at org.apache.spark.repl.Main$.main(Main.scala:31)
        at org.apache.spark.repl.Main.main(Main.scala)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:606)
        at org.apache.spark.deploy.SparkSubmit$.launch(SparkSubmit.scala:358)
        at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:75)
        at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
15/10/17 18:42:23 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/stages/stage/kill,null}
15/10/17 18:42:23 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/,null}
15/10/17 18:42:23 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/static,null}
15/10/17 18:42:23 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/executors/threadDump/json,null}
15/10/17 18:42:23 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/executors/threadDump,null}
15/10/17 18:42:23 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/executors/json,null}
15/10/17 18:42:23 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/executors,null}
15/10/17 18:42:23 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/environment/json,null}
15/10/17 18:42:23 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/environment,null}
15/10/17 18:42:23 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/storage/rdd/json,null}
15/10/17 18:42:23 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/storage/rdd,null}
15/10/17 18:42:23 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/storage/json,null}
15/10/17 18:42:23 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/storage,null}
15/10/17 18:42:23 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/stages/pool/json,null}
15/10/17 18:42:23 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/stages/pool,null}
15/10/17 18:42:23 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/stages/stage/json,null}
15/10/17 18:42:23 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/stages/stage,null}
15/10/17 18:42:23 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/stages/json,null}
15/10/17 18:42:23 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/stages,null}
15/10/17 18:42:23 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/jobs/job/json,null}
15/10/17 18:42:23 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/jobs/job,null}
15/10/17 18:42:23 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/jobs/json,null}
15/10/17 18:42:23 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/jobs,null}
15/10/17 18:42:23 WARN util.Utils: Service 'SparkUI' could not bind on port 4044. Attempting port 4045.
15/10/17 18:42:23 INFO server.Server: jetty-8.y.z-SNAPSHOT
15/10/17 18:42:23 WARN component.AbstractLifeCycle: FAILED SelectChannelConnector@0.0.0.0:4045: java.net.BindException: Address already in use
java.net.BindException: Address already in use
        at sun.nio.ch.Net.bind0(Native Method)
        at sun.nio.ch.Net.bind(Net.java:444)
        at sun.nio.ch.Net.bind(Net.java:436)
        at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:214)
        at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
        at org.eclipse.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
        at org.eclipse.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
        at org.eclipse.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
        at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
        at org.eclipse.jetty.server.Server.doStart(Server.java:293)
        at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
        at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:194)
        at org.apache.spark.ui.JettyUtils$$anonfun$2.apply(JettyUtils.scala:204)
        at org.apache.spark.ui.JettyUtils$$anonfun$2.apply(JettyUtils.scala:204)
        at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1676)
        at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
        at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1667)
        at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:204)
        at org.apache.spark.ui.WebUI.bind(WebUI.scala:102)
        at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:269)
        at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:269)
        at scala.Option.foreach(Option.scala:236)
        at org.apache.spark.SparkContext.<init>(SparkContext.scala:269)
        at org.apache.spark.repl.SparkILoop.createSparkContext(SparkILoop.scala:986)
        at $line3.$read$$iwC$$iwC.<init>(<console>:9)
        at $line3.$read$$iwC.<init>(<console>:18)
        at $line3.$read.<init>(<console>:20)
        at $line3.$read$.<init>(<console>:24)
        at $line3.$read$.<clinit>(<console>)
        at $line3.$eval$.<init>(<console>:7)
        at $line3.$eval$.<clinit>(<console>)
        at $line3.$eval.$print(<console>)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:606)
        at org.apache.spark.repl.SparkIMain$ReadEvalPrint.call(SparkIMain.scala:852)
        at org.apache.spark.repl.SparkIMain$Request.loadAndRun(SparkIMain.scala:1125)
        at org.apache.spark.repl.SparkIMain.loadAndRunReq$1(SparkIMain.scala:674)
        at org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:705)
        at org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:669)
        at org.apache.spark.repl.SparkILoop.reallyInterpret$1(SparkILoop.scala:828)
        at org.apache.spark.repl.SparkILoop.interpretStartingWith(SparkILoop.scala:873)
        at org.apache.spark.repl.SparkILoop.command(SparkILoop.scala:785)
        at org.apache.spark.repl.SparkILoopInit$$anonfun$initializeSpark$1.apply(SparkILoopInit.scala:123)
        at org.apache.spark.repl.SparkILoopInit$$anonfun$initializeSpark$1.apply(SparkILoopInit.scala:122)
        at org.apache.spark.repl.SparkIMain.beQuietDuring(SparkIMain.scala:270)
        at org.apache.spark.repl.SparkILoopInit$class.initializeSpark(SparkILoopInit.scala:122)
        at org.apache.spark.repl.SparkILoop.initializeSpark(SparkILoop.scala:60)
        at org.apache.spark.repl.SparkILoop$$anonfun$process$1$$anonfun$apply$mcZ$sp$5.apply$mcV$sp(SparkILoop.scala:945)
        at org.apache.spark.repl.SparkILoopInit$class.runThunks(SparkILoopInit.scala:147)
        at org.apache.spark.repl.SparkILoop.runThunks(SparkILoop.scala:60)
        at org.apache.spark.repl.SparkILoopInit$class.postInitialization(SparkILoopInit.scala:106)
        at org.apache.spark.repl.SparkILoop.postInitialization(SparkILoop.scala:60)
        at org.apache.spark.repl.SparkILoop$$anonfun$process$1.apply$mcZ$sp(SparkILoop.scala:962)
        at org.apache.spark.repl.SparkILoop$$anonfun$process$1.apply(SparkILoop.scala:916)
        at org.apache.spark.repl.SparkILoop$$anonfun$process$1.apply(SparkILoop.scala:916)
        at scala.tools.nsc.util.ScalaClassLoader$.savingContextLoader(ScalaClassLoader.scala:135)
        at org.apache.spark.repl.SparkILoop.process(SparkILoop.scala:916)
        at org.apache.spark.repl.SparkILoop.process(SparkILoop.scala:1011)
        at org.apache.spark.repl.Main$.main(Main.scala:31)
        at org.apache.spark.repl.Main.main(Main.scala)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:606)
        at org.apache.spark.deploy.SparkSubmit$.launch(SparkSubmit.scala:358)
        at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:75)
        at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
15/10/17 18:42:23 WARN component.AbstractLifeCycle: FAILED org.eclipse.jetty.server.Server@7eeabe71: java.net.BindException: Address already in use
java.net.BindException: Address already in use
        at sun.nio.ch.Net.bind0(Native Method)
        at sun.nio.ch.Net.bind(Net.java:444)
        at sun.nio.ch.Net.bind(Net.java:436)
        at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:214)
        at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
        at org.eclipse.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
        at org.eclipse.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
        at org.eclipse.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
        at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
        at org.eclipse.jetty.server.Server.doStart(Server.java:293)
        at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
        at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:194)
        at org.apache.spark.ui.JettyUtils$$anonfun$2.apply(JettyUtils.scala:204)
        at org.apache.spark.ui.JettyUtils$$anonfun$2.apply(JettyUtils.scala:204)
        at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1676)
        at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
        at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1667)
        at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:204)
        at org.apache.spark.ui.WebUI.bind(WebUI.scala:102)
        at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:269)
        at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:269)
        at scala.Option.foreach(Option.scala:236)
        at org.apache.spark.SparkContext.<init>(SparkContext.scala:269)
        at org.apache.spark.repl.SparkILoop.createSparkContext(SparkILoop.scala:986)
        at $line3.$read$$iwC$$iwC.<init>(<console>:9)
        at $line3.$read$$iwC.<init>(<console>:18)
        at $line3.$read.<init>(<console>:20)
        at $line3.$read$.<init>(<console>:24)
        at $line3.$read$.<clinit>(<console>)
        at $line3.$eval$.<init>(<console>:7)
        at $line3.$eval$.<clinit>(<console>)
        at $line3.$eval.$print(<console>)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:606)
        at org.apache.spark.repl.SparkIMain$ReadEvalPrint.call(SparkIMain.scala:852)
        at org.apache.spark.repl.SparkIMain$Request.loadAndRun(SparkIMain.scala:1125)
        at org.apache.spark.repl.SparkIMain.loadAndRunReq$1(SparkIMain.scala:674)
        at org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:705)
        at org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:669)
        at org.apache.spark.repl.SparkILoop.reallyInterpret$1(SparkILoop.scala:828)
        at org.apache.spark.repl.SparkILoop.interpretStartingWith(SparkILoop.scala:873)
        at org.apache.spark.repl.SparkILoop.command(SparkILoop.scala:785)
        at org.apache.spark.repl.SparkILoopInit$$anonfun$initializeSpark$1.apply(SparkILoopInit.scala:123)
        at org.apache.spark.repl.SparkILoopInit$$anonfun$initializeSpark$1.apply(SparkILoopInit.scala:122)
        at org.apache.spark.repl.SparkIMain.beQuietDuring(SparkIMain.scala:270)
        at org.apache.spark.repl.SparkILoopInit$class.initializeSpark(SparkILoopInit.scala:122)
        at org.apache.spark.repl.SparkILoop.initializeSpark(SparkILoop.scala:60)
        at org.apache.spark.repl.SparkILoop$$anonfun$process$1$$anonfun$apply$mcZ$sp$5.apply$mcV$sp(SparkILoop.scala:945)
        at org.apache.spark.repl.SparkILoopInit$class.runThunks(SparkILoopInit.scala:147)
        at org.apache.spark.repl.SparkILoop.runThunks(SparkILoop.scala:60)
        at org.apache.spark.repl.SparkILoopInit$class.postInitialization(SparkILoopInit.scala:106)
        at org.apache.spark.repl.SparkILoop.postInitialization(SparkILoop.scala:60)
        at org.apache.spark.repl.SparkILoop$$anonfun$process$1.apply$mcZ$sp(SparkILoop.scala:962)
        at org.apache.spark.repl.SparkILoop$$anonfun$process$1.apply(SparkILoop.scala:916)
        at org.apache.spark.repl.SparkILoop$$anonfun$process$1.apply(SparkILoop.scala:916)
        at scala.tools.nsc.util.ScalaClassLoader$.savingContextLoader(ScalaClassLoader.scala:135)
        at org.apache.spark.repl.SparkILoop.process(SparkILoop.scala:916)
        at org.apache.spark.repl.SparkILoop.process(SparkILoop.scala:1011)
        at org.apache.spark.repl.Main$.main(Main.scala:31)
        at org.apache.spark.repl.Main.main(Main.scala)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:606)
        at org.apache.spark.deploy.SparkSubmit$.launch(SparkSubmit.scala:358)
        at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:75)
        at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
15/10/17 18:42:23 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/stages/stage/kill,null}
15/10/17 18:42:23 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/,null}
15/10/17 18:42:23 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/static,null}
15/10/17 18:42:23 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/executors/threadDump/json,null}
15/10/17 18:42:23 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/executors/threadDump,null}
15/10/17 18:42:23 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/executors/json,null}
15/10/17 18:42:23 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/executors,null}
15/10/17 18:42:23 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/environment/json,null}
15/10/17 18:42:23 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/environment,null}
15/10/17 18:42:23 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/storage/rdd/json,null}
15/10/17 18:42:23 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/storage/rdd,null}
15/10/17 18:42:23 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/storage/json,null}
15/10/17 18:42:23 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/storage,null}
15/10/17 18:42:23 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/stages/pool/json,null}
15/10/17 18:42:23 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/stages/pool,null}
15/10/17 18:42:23 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/stages/stage/json,null}
15/10/17 18:42:23 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/stages/stage,null}
15/10/17 18:42:23 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/stages/json,null}
15/10/17 18:42:23 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/stages,null}
15/10/17 18:42:23 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/jobs/job/json,null}
15/10/17 18:42:23 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/jobs/job,null}
15/10/17 18:42:23 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/jobs/json,null}
15/10/17 18:42:23 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/jobs,null}
15/10/17 18:42:23 WARN util.Utils: Service 'SparkUI' could not bind on port 4045. Attempting port 4046.
15/10/17 18:42:23 INFO server.Server: jetty-8.y.z-SNAPSHOT
15/10/17 18:42:23 WARN component.AbstractLifeCycle: FAILED SelectChannelConnector@0.0.0.0:4046: java.net.BindException: Address already in use
java.net.BindException: Address already in use
        at sun.nio.ch.Net.bind0(Native Method)
        at sun.nio.ch.Net.bind(Net.java:444)
        at sun.nio.ch.Net.bind(Net.java:436)
        at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:214)
        at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
        at org.eclipse.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
        at org.eclipse.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
        at org.eclipse.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
        at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
        at org.eclipse.jetty.server.Server.doStart(Server.java:293)
        at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
        at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:194)
        at org.apache.spark.ui.JettyUtils$$anonfun$2.apply(JettyUtils.scala:204)
        at org.apache.spark.ui.JettyUtils$$anonfun$2.apply(JettyUtils.scala:204)
        at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1676)
        at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
        at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1667)
        at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:204)
        at org.apache.spark.ui.WebUI.bind(WebUI.scala:102)
        at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:269)
        at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:269)
        at scala.Option.foreach(Option.scala:236)
        at org.apache.spark.SparkContext.<init>(SparkContext.scala:269)
        at org.apache.spark.repl.SparkILoop.createSparkContext(SparkILoop.scala:986)
        at $line3.$read$$iwC$$iwC.<init>(<console>:9)
        at $line3.$read$$iwC.<init>(<console>:18)
        at $line3.$read.<init>(<console>:20)
        at $line3.$read$.<init>(<console>:24)
        at $line3.$read$.<clinit>(<console>)
        at $line3.$eval$.<init>(<console>:7)
        at $line3.$eval$.<clinit>(<console>)
        at $line3.$eval.$print(<console>)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:606)
        at org.apache.spark.repl.SparkIMain$ReadEvalPrint.call(SparkIMain.scala:852)
        at org.apache.spark.repl.SparkIMain$Request.loadAndRun(SparkIMain.scala:1125)
        at org.apache.spark.repl.SparkIMain.loadAndRunReq$1(SparkIMain.scala:674)
        at org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:705)
        at org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:669)
        at org.apache.spark.repl.SparkILoop.reallyInterpret$1(SparkILoop.scala:828)
        at org.apache.spark.repl.SparkILoop.interpretStartingWith(SparkILoop.scala:873)
        at org.apache.spark.repl.SparkILoop.command(SparkILoop.scala:785)
        at org.apache.spark.repl.SparkILoopInit$$anonfun$initializeSpark$1.apply(SparkILoopInit.scala:123)
        at org.apache.spark.repl.SparkILoopInit$$anonfun$initializeSpark$1.apply(SparkILoopInit.scala:122)
        at org.apache.spark.repl.SparkIMain.beQuietDuring(SparkIMain.scala:270)
        at org.apache.spark.repl.SparkILoopInit$class.initializeSpark(SparkILoopInit.scala:122)
        at org.apache.spark.repl.SparkILoop.initializeSpark(SparkILoop.scala:60)
        at org.apache.spark.repl.SparkILoop$$anonfun$process$1$$anonfun$apply$mcZ$sp$5.apply$mcV$sp(SparkILoop.scala:945)
        at org.apache.spark.repl.SparkILoopInit$class.runThunks(SparkILoopInit.scala:147)
        at org.apache.spark.repl.SparkILoop.runThunks(SparkILoop.scala:60)
        at org.apache.spark.repl.SparkILoopInit$class.postInitialization(SparkILoopInit.scala:106)
        at org.apache.spark.repl.SparkILoop.postInitialization(SparkILoop.scala:60)
        at org.apache.spark.repl.SparkILoop$$anonfun$process$1.apply$mcZ$sp(SparkILoop.scala:962)
        at org.apache.spark.repl.SparkILoop$$anonfun$process$1.apply(SparkILoop.scala:916)
        at org.apache.spark.repl.SparkILoop$$anonfun$process$1.apply(SparkILoop.scala:916)
        at scala.tools.nsc.util.ScalaClassLoader$.savingContextLoader(ScalaClassLoader.scala:135)
        at org.apache.spark.repl.SparkILoop.process(SparkILoop.scala:916)
        at org.apache.spark.repl.SparkILoop.process(SparkILoop.scala:1011)
        at org.apache.spark.repl.Main$.main(Main.scala:31)
        at org.apache.spark.repl.Main.main(Main.scala)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:606)
        at org.apache.spark.deploy.SparkSubmit$.launch(SparkSubmit.scala:358)
        at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:75)
        at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
15/10/17 18:42:23 WARN component.AbstractLifeCycle: FAILED org.eclipse.jetty.server.Server@1634b1c8: java.net.BindException: Address already in use
java.net.BindException: Address already in use
        at sun.nio.ch.Net.bind0(Native Method)
        at sun.nio.ch.Net.bind(Net.java:444)
        at sun.nio.ch.Net.bind(Net.java:436)
        at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:214)
        at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
        at org.eclipse.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
        at org.eclipse.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
        at org.eclipse.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
        at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
        at org.eclipse.jetty.server.Server.doStart(Server.java:293)
        at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
        at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:194)
        at org.apache.spark.ui.JettyUtils$$anonfun$2.apply(JettyUtils.scala:204)
        at org.apache.spark.ui.JettyUtils$$anonfun$2.apply(JettyUtils.scala:204)
        at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1676)
        at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
        at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1667)
        at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:204)
        at org.apache.spark.ui.WebUI.bind(WebUI.scala:102)
        at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:269)
        at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:269)
        at scala.Option.foreach(Option.scala:236)
        at org.apache.spark.SparkContext.<init>(SparkContext.scala:269)
        at org.apache.spark.repl.SparkILoop.createSparkContext(SparkILoop.scala:986)
        at $line3.$read$$iwC$$iwC.<init>(<console>:9)
        at $line3.$read$$iwC.<init>(<console>:18)
        at $line3.$read.<init>(<console>:20)
        at $line3.$read$.<init>(<console>:24)
        at $line3.$read$.<clinit>(<console>)
        at $line3.$eval$.<init>(<console>:7)
        at $line3.$eval$.<clinit>(<console>)
        at $line3.$eval.$print(<console>)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:606)
        at org.apache.spark.repl.SparkIMain$ReadEvalPrint.call(SparkIMain.scala:852)
        at org.apache.spark.repl.SparkIMain$Request.loadAndRun(SparkIMain.scala:1125)
        at org.apache.spark.repl.SparkIMain.loadAndRunReq$1(SparkIMain.scala:674)
        at org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:705)
        at org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:669)
        at org.apache.spark.repl.SparkILoop.reallyInterpret$1(SparkILoop.scala:828)
        at org.apache.spark.repl.SparkILoop.interpretStartingWith(SparkILoop.scala:873)
        at org.apache.spark.repl.SparkILoop.command(SparkILoop.scala:785)
        at org.apache.spark.repl.SparkILoopInit$$anonfun$initializeSpark$1.apply(SparkILoopInit.scala:123)
        at org.apache.spark.repl.SparkILoopInit$$anonfun$initializeSpark$1.apply(SparkILoopInit.scala:122)
        at org.apache.spark.repl.SparkIMain.beQuietDuring(SparkIMain.scala:270)
        at org.apache.spark.repl.SparkILoopInit$class.initializeSpark(SparkILoopInit.scala:122)
        at org.apache.spark.repl.SparkILoop.initializeSpark(SparkILoop.scala:60)
        at org.apache.spark.repl.SparkILoop$$anonfun$process$1$$anonfun$apply$mcZ$sp$5.apply$mcV$sp(SparkILoop.scala:945)
        at org.apache.spark.repl.SparkILoopInit$class.runThunks(SparkILoopInit.scala:147)
        at org.apache.spark.repl.SparkILoop.runThunks(SparkILoop.scala:60)
        at org.apache.spark.repl.SparkILoopInit$class.postInitialization(SparkILoopInit.scala:106)
        at org.apache.spark.repl.SparkILoop.postInitialization(SparkILoop.scala:60)
        at org.apache.spark.repl.SparkILoop$$anonfun$process$1.apply$mcZ$sp(SparkILoop.scala:962)
        at org.apache.spark.repl.SparkILoop$$anonfun$process$1.apply(SparkILoop.scala:916)
        at org.apache.spark.repl.SparkILoop$$anonfun$process$1.apply(SparkILoop.scala:916)
        at scala.tools.nsc.util.ScalaClassLoader$.savingContextLoader(ScalaClassLoader.scala:135)
        at org.apache.spark.repl.SparkILoop.process(SparkILoop.scala:916)
        at org.apache.spark.repl.SparkILoop.process(SparkILoop.scala:1011)
        at org.apache.spark.repl.Main$.main(Main.scala:31)
        at org.apache.spark.repl.Main.main(Main.scala)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:606)
        at org.apache.spark.deploy.SparkSubmit$.launch(SparkSubmit.scala:358)
        at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:75)
        at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
15/10/17 18:42:23 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/stages/stage/kill,null}
15/10/17 18:42:23 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/,null}
15/10/17 18:42:23 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/static,null}
15/10/17 18:42:23 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/executors/threadDump/json,null}
15/10/17 18:42:23 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/executors/threadDump,null}
15/10/17 18:42:23 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/executors/json,null}
15/10/17 18:42:23 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/executors,null}
15/10/17 18:42:23 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/environment/json,null}
15/10/17 18:42:23 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/environment,null}
15/10/17 18:42:23 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/storage/rdd/json,null}
15/10/17 18:42:23 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/storage/rdd,null}
15/10/17 18:42:23 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/storage/json,null}
15/10/17 18:42:23 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/storage,null}
15/10/17 18:42:23 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/stages/pool/json,null}
15/10/17 18:42:23 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/stages/pool,null}
15/10/17 18:42:23 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/stages/stage/json,null}
15/10/17 18:42:23 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/stages/stage,null}
15/10/17 18:42:23 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/stages/json,null}
15/10/17 18:42:23 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/stages,null}
15/10/17 18:42:23 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/jobs/job/json,null}
15/10/17 18:42:23 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/jobs/job,null}
15/10/17 18:42:23 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/jobs/json,null}
15/10/17 18:42:23 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/jobs,null}
15/10/17 18:42:24 WARN util.Utils: Service 'SparkUI' could not bind on port 4046. Attempting port 4047.
15/10/17 18:42:24 INFO server.Server: jetty-8.y.z-SNAPSHOT
15/10/17 18:42:24 WARN component.AbstractLifeCycle: FAILED SelectChannelConnector@0.0.0.0:4047: java.net.BindException: Address already in use
java.net.BindException: Address already in use
        at sun.nio.ch.Net.bind0(Native Method)
        at sun.nio.ch.Net.bind(Net.java:444)
        at sun.nio.ch.Net.bind(Net.java:436)
        at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:214)
        at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
        at org.eclipse.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
        at org.eclipse.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
        at org.eclipse.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
        at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
        at org.eclipse.jetty.server.Server.doStart(Server.java:293)
        at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
        at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:194)
        at org.apache.spark.ui.JettyUtils$$anonfun$2.apply(JettyUtils.scala:204)
        at org.apache.spark.ui.JettyUtils$$anonfun$2.apply(JettyUtils.scala:204)
        at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1676)
        at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
        at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1667)
        at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:204)
        at org.apache.spark.ui.WebUI.bind(WebUI.scala:102)
        at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:269)
        at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:269)
        at scala.Option.foreach(Option.scala:236)
        at org.apache.spark.SparkContext.<init>(SparkContext.scala:269)
        at org.apache.spark.repl.SparkILoop.createSparkContext(SparkILoop.scala:986)
        at $line3.$read$$iwC$$iwC.<init>(<console>:9)
        at $line3.$read$$iwC.<init>(<console>:18)
        at $line3.$read.<init>(<console>:20)
        at $line3.$read$.<init>(<console>:24)
        at $line3.$read$.<clinit>(<console>)
        at $line3.$eval$.<init>(<console>:7)
        at $line3.$eval$.<clinit>(<console>)
        at $line3.$eval.$print(<console>)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:606)
        at org.apache.spark.repl.SparkIMain$ReadEvalPrint.call(SparkIMain.scala:852)
        at org.apache.spark.repl.SparkIMain$Request.loadAndRun(SparkIMain.scala:1125)
        at org.apache.spark.repl.SparkIMain.loadAndRunReq$1(SparkIMain.scala:674)
        at org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:705)
        at org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:669)
        at org.apache.spark.repl.SparkILoop.reallyInterpret$1(SparkILoop.scala:828)
        at org.apache.spark.repl.SparkILoop.interpretStartingWith(SparkILoop.scala:873)
        at org.apache.spark.repl.SparkILoop.command(SparkILoop.scala:785)
        at org.apache.spark.repl.SparkILoopInit$$anonfun$initializeSpark$1.apply(SparkILoopInit.scala:123)
        at org.apache.spark.repl.SparkILoopInit$$anonfun$initializeSpark$1.apply(SparkILoopInit.scala:122)
        at org.apache.spark.repl.SparkIMain.beQuietDuring(SparkIMain.scala:270)
        at org.apache.spark.repl.SparkILoopInit$class.initializeSpark(SparkILoopInit.scala:122)
        at org.apache.spark.repl.SparkILoop.initializeSpark(SparkILoop.scala:60)
        at org.apache.spark.repl.SparkILoop$$anonfun$process$1$$anonfun$apply$mcZ$sp$5.apply$mcV$sp(SparkILoop.scala:945)
        at org.apache.spark.repl.SparkILoopInit$class.runThunks(SparkILoopInit.scala:147)
        at org.apache.spark.repl.SparkILoop.runThunks(SparkILoop.scala:60)
        at org.apache.spark.repl.SparkILoopInit$class.postInitialization(SparkILoopInit.scala:106)
        at org.apache.spark.repl.SparkILoop.postInitialization(SparkILoop.scala:60)
        at org.apache.spark.repl.SparkILoop$$anonfun$process$1.apply$mcZ$sp(SparkILoop.scala:962)
        at org.apache.spark.repl.SparkILoop$$anonfun$process$1.apply(SparkILoop.scala:916)
        at org.apache.spark.repl.SparkILoop$$anonfun$process$1.apply(SparkILoop.scala:916)
        at scala.tools.nsc.util.ScalaClassLoader$.savingContextLoader(ScalaClassLoader.scala:135)
        at org.apache.spark.repl.SparkILoop.process(SparkILoop.scala:916)
        at org.apache.spark.repl.SparkILoop.process(SparkILoop.scala:1011)
        at org.apache.spark.repl.Main$.main(Main.scala:31)
        at org.apache.spark.repl.Main.main(Main.scala)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:606)
        at org.apache.spark.deploy.SparkSubmit$.launch(SparkSubmit.scala:358)
        at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:75)
        at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
15/10/17 18:42:24 WARN component.AbstractLifeCycle: FAILED org.eclipse.jetty.server.Server@84644a2: java.net.BindException: Address already in use
java.net.BindException: Address already in use
        at sun.nio.ch.Net.bind0(Native Method)
        at sun.nio.ch.Net.bind(Net.java:444)
        at sun.nio.ch.Net.bind(Net.java:436)
        at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:214)
        at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
        at org.eclipse.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
        at org.eclipse.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
        at org.eclipse.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
        at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
        at org.eclipse.jetty.server.Server.doStart(Server.java:293)
        at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
        at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:194)
        at org.apache.spark.ui.JettyUtils$$anonfun$2.apply(JettyUtils.scala:204)
        at org.apache.spark.ui.JettyUtils$$anonfun$2.apply(JettyUtils.scala:204)
        at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1676)
        at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
        at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1667)
        at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:204)
        at org.apache.spark.ui.WebUI.bind(WebUI.scala:102)
        at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:269)
        at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:269)
        at scala.Option.foreach(Option.scala:236)
        at org.apache.spark.SparkContext.<init>(SparkContext.scala:269)
        at org.apache.spark.repl.SparkILoop.createSparkContext(SparkILoop.scala:986)
        at $line3.$read$$iwC$$iwC.<init>(<console>:9)
        at $line3.$read$$iwC.<init>(<console>:18)
        at $line3.$read.<init>(<console>:20)
        at $line3.$read$.<init>(<console>:24)
        at $line3.$read$.<clinit>(<console>)
        at $line3.$eval$.<init>(<console>:7)
        at $line3.$eval$.<clinit>(<console>)
        at $line3.$eval.$print(<console>)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:606)
        at org.apache.spark.repl.SparkIMain$ReadEvalPrint.call(SparkIMain.scala:852)
        at org.apache.spark.repl.SparkIMain$Request.loadAndRun(SparkIMain.scala:1125)
        at org.apache.spark.repl.SparkIMain.loadAndRunReq$1(SparkIMain.scala:674)
        at org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:705)
        at org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:669)
        at org.apache.spark.repl.SparkILoop.reallyInterpret$1(SparkILoop.scala:828)
        at org.apache.spark.repl.SparkILoop.interpretStartingWith(SparkILoop.scala:873)
        at org.apache.spark.repl.SparkILoop.command(SparkILoop.scala:785)
        at org.apache.spark.repl.SparkILoopInit$$anonfun$initializeSpark$1.apply(SparkILoopInit.scala:123)
        at org.apache.spark.repl.SparkILoopInit$$anonfun$initializeSpark$1.apply(SparkILoopInit.scala:122)
        at org.apache.spark.repl.SparkIMain.beQuietDuring(SparkIMain.scala:270)
        at org.apache.spark.repl.SparkILoopInit$class.initializeSpark(SparkILoopInit.scala:122)
        at org.apache.spark.repl.SparkILoop.initializeSpark(SparkILoop.scala:60)
        at org.apache.spark.repl.SparkILoop$$anonfun$process$1$$anonfun$apply$mcZ$sp$5.apply$mcV$sp(SparkILoop.scala:945)
        at org.apache.spark.repl.SparkILoopInit$class.runThunks(SparkILoopInit.scala:147)
        at org.apache.spark.repl.SparkILoop.runThunks(SparkILoop.scala:60)
        at org.apache.spark.repl.SparkILoopInit$class.postInitialization(SparkILoopInit.scala:106)
        at org.apache.spark.repl.SparkILoop.postInitialization(SparkILoop.scala:60)
        at org.apache.spark.repl.SparkILoop$$anonfun$process$1.apply$mcZ$sp(SparkILoop.scala:962)
        at org.apache.spark.repl.SparkILoop$$anonfun$process$1.apply(SparkILoop.scala:916)
        at org.apache.spark.repl.SparkILoop$$anonfun$process$1.apply(SparkILoop.scala:916)
        at scala.tools.nsc.util.ScalaClassLoader$.savingContextLoader(ScalaClassLoader.scala:135)
        at org.apache.spark.repl.SparkILoop.process(SparkILoop.scala:916)
        at org.apache.spark.repl.SparkILoop.process(SparkILoop.scala:1011)
        at org.apache.spark.repl.Main$.main(Main.scala:31)
        at org.apache.spark.repl.Main.main(Main.scala)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:606)
        at org.apache.spark.deploy.SparkSubmit$.launch(SparkSubmit.scala:358)
        at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:75)
        at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
15/10/17 18:42:24 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/stages/stage/kill,null}
15/10/17 18:42:24 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/,null}
15/10/17 18:42:24 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/static,null}
15/10/17 18:42:24 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/executors/threadDump/json,null}
15/10/17 18:42:24 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/executors/threadDump,null}
15/10/17 18:42:24 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/executors/json,null}
15/10/17 18:42:24 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/executors,null}
15/10/17 18:42:24 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/environment/json,null}
15/10/17 18:42:24 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/environment,null}
15/10/17 18:42:24 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/storage/rdd/json,null}
15/10/17 18:42:24 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/storage/rdd,null}
15/10/17 18:42:24 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/storage/json,null}
15/10/17 18:42:24 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/storage,null}
15/10/17 18:42:24 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/stages/pool/json,null}
15/10/17 18:42:24 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/stages/pool,null}
15/10/17 18:42:24 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/stages/stage/json,null}
15/10/17 18:42:24 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/stages/stage,null}
15/10/17 18:42:24 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/stages/json,null}
15/10/17 18:42:24 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/stages,null}
15/10/17 18:42:24 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/jobs/job/json,null}
15/10/17 18:42:24 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/jobs/job,null}
15/10/17 18:42:24 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/jobs/json,null}
15/10/17 18:42:24 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/jobs,null}
15/10/17 18:42:24 WARN util.Utils: Service 'SparkUI' could not bind on port 4047. Attempting port 4048.
15/10/17 18:42:24 INFO server.Server: jetty-8.y.z-SNAPSHOT
15/10/17 18:42:24 INFO server.AbstractConnector: Started SelectChannelConnector@0.0.0.0:4048
15/10/17 18:42:24 INFO util.Utils: Successfully started service 'SparkUI' on port 4048.
15/10/17 18:42:24 INFO ui.SparkUI: Started SparkUI at http://cs6360.utdallas.edu:4048
15/10/17 18:42:24 INFO client.RMProxy: Connecting to ResourceManager at cshadoop1.utdallas.edu/10.176.92.71:8032
15/10/17 18:42:24 INFO yarn.Client: Requesting a new application from cluster with 8 NodeManagers
15/10/17 18:42:24 INFO yarn.Client: Verifying our application has not requested more than the maximum memory capability of the cluster (8192 MB per container)
15/10/17 18:42:24 INFO yarn.Client: Will allocate AM container, with 896 MB memory including 384 MB overhead
15/10/17 18:42:24 INFO yarn.Client: Setting up container launch context for our AM
15/10/17 18:42:24 INFO yarn.Client: Preparing resources for our AM container
15/10/17 18:42:25 INFO yarn.Client: Uploading resource file:/usr/local/spark-1.2.0-bin-hadoop2.4/lib/spark-assembly-1.2.0-hadoop2.4.0.jar -> hdfs://cshadoop1/user/jkb140130/.sparkStaging/application_1444046496659_0969/spark-assembly-1.2.0-hadoop2.4.0.jar
15/10/17 18:42:29 INFO yarn.Client: Setting up the launch environment for our AM container
15/10/17 18:42:29 INFO spark.SecurityManager: Changing view acls to: jkb140130
15/10/17 18:42:29 INFO spark.SecurityManager: Changing modify acls to: jkb140130
15/10/17 18:42:29 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(jkb140130); users with modify permissions: Set(jkb140130)
15/10/17 18:42:29 INFO yarn.Client: Submitting application 969 to ResourceManager
15/10/17 18:42:29 INFO impl.YarnClientImpl: Submitted application application_1444046496659_0969
15/10/17 18:42:30 INFO yarn.Client: Application report for application_1444046496659_0969 (state: ACCEPTED)
15/10/17 18:42:30 INFO yarn.Client:
         client token: N/A
         diagnostics: N/A
         ApplicationMaster host: N/A
         ApplicationMaster RPC port: -1
         queue: default
         start time: 1445125349177
         final status: UNDEFINED
         tracking URL: http://cshadoop1.utdallas.edu:8088/proxy/application_1444046496659_0969/
         user: jkb140130
15/10/17 18:42:31 INFO yarn.Client: Application report for application_1444046496659_0969 (state: ACCEPTED)
15/10/17 18:42:32 INFO yarn.Client: Application report for application_1444046496659_0969 (state: ACCEPTED)
15/10/17 18:42:33 INFO yarn.Client: Application report for application_1444046496659_0969 (state: ACCEPTED)
15/10/17 18:42:34 INFO yarn.Client: Application report for application_1444046496659_0969 (state: ACCEPTED)
15/10/17 18:42:34 INFO cluster.YarnClientSchedulerBackend: ApplicationMaster registered as Actor[akka.tcp://sparkYarnAM@cshadoop7.utdallas.edu:56229/user/YarnAM#-38425814]
15/10/17 18:42:34 INFO cluster.YarnClientSchedulerBackend: Add WebUI Filter. org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter, Map(PROXY_HOSTS -> cshadoop1.utdallas.edu, PROXY_URI_BASES -> http://cshadoop1.utdallas.edu:8088/proxy/application_1444046496659_0969), /proxy/application_1444046496659_0969
15/10/17 18:42:34 INFO ui.JettyUtils: Adding filter: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
15/10/17 18:42:35 INFO yarn.Client: Application report for application_1444046496659_0969 (state: RUNNING)
15/10/17 18:42:35 INFO yarn.Client:
         client token: N/A
         diagnostics: N/A
         ApplicationMaster host: cshadoop7.utdallas.edu
         ApplicationMaster RPC port: 0
         queue: default
         start time: 1445125349177
         final status: UNDEFINED
         tracking URL: http://cshadoop1.utdallas.edu:8088/proxy/application_1444046496659_0969/
         user: jkb140130
15/10/17 18:42:35 INFO cluster.YarnClientSchedulerBackend: Application application_1444046496659_0969 has started running.
15/10/17 18:42:35 INFO netty.NettyBlockTransferService: Server created on 49171
15/10/17 18:42:35 INFO storage.BlockManagerMaster: Trying to register BlockManager
15/10/17 18:42:35 INFO storage.BlockManagerMasterActor: Registering block manager cs6360.utdallas.edu:49171 with 265.4 MB RAM, BlockManagerId(<driver>, cs6360.utdallas.edu, 49171)
15/10/17 18:42:35 INFO storage.BlockManagerMaster: Registered BlockManager
15/10/17 18:42:45 INFO cluster.YarnClientSchedulerBackend: Registered executor: Actor[akka.tcp://sparkExecutor@cshadoop5.utdallas.edu:55451/user/Executor#-161927098] with ID 1
15/10/17 18:42:46 INFO util.RackResolver: Resolved cshadoop5.utdallas.edu to /default-rack
15/10/17 18:42:46 INFO storage.BlockManagerMasterActor: Registering block manager cshadoop5.utdallas.edu:54305 with 1060.3 MB RAM, BlockManagerId(1, cshadoop5.utdallas.edu, 54305)
15/10/17 18:42:47 INFO cluster.YarnClientSchedulerBackend: Registered executor: Actor[akka.tcp://sparkExecutor@cshadoop8.utdallas.edu:47316/user/Executor#1744300672] with ID 4
15/10/17 18:42:47 INFO util.RackResolver: Resolved cshadoop8.utdallas.edu to /default-rack
15/10/17 18:42:47 INFO cluster.YarnClientSchedulerBackend: Registered executor: Actor[akka.tcp://sparkExecutor@cshadoop3.utdallas.edu:35004/user/Executor#472601810] with ID 3
15/10/17 18:42:47 INFO util.RackResolver: Resolved cshadoop3.utdallas.edu to /default-rack
15/10/17 18:42:47 INFO cluster.YarnClientSchedulerBackend: Registered executor: Actor[akka.tcp://sparkExecutor@cshadoop4.utdallas.edu:56054/user/Executor#-377601796] with ID 2
15/10/17 18:42:47 INFO util.RackResolver: Resolved cshadoop4.utdallas.edu to /default-rack
15/10/17 18:42:48 INFO storage.BlockManagerMasterActor: Registering block manager cshadoop8.utdallas.edu:58927 with 1060.3 MB RAM, BlockManagerId(4, cshadoop8.utdallas.edu, 58927)
15/10/17 18:42:48 INFO storage.BlockManagerMasterActor: Registering block manager cshadoop4.utdallas.edu:59635 with 1060.3 MB RAM, BlockManagerId(2, cshadoop4.utdallas.edu, 59635)
15/10/17 18:42:48 INFO storage.BlockManagerMasterActor: Registering block manager cshadoop3.utdallas.edu:54376 with 1060.3 MB RAM, BlockManagerId(3, cshadoop3.utdallas.edu, 54376)
15/10/17 18:42:49 INFO cluster.YarnClientSchedulerBackend: Registered executor: Actor[akka.tcp://sparkExecutor@cshadoop2.utdallas.edu:37446/user/Executor#1374785507] with ID 5
15/10/17 18:42:49 INFO util.RackResolver: Resolved cshadoop2.utdallas.edu to /default-rack
15/10/17 18:42:49 INFO cluster.YarnClientSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.8
15/10/17 18:42:49 INFO repl.SparkILoop: Created spark context..
Spark context available as sc.
15/10/17 18:42:49 INFO cluster.YarnClientSchedulerBackend: Registered executor: Actor[akka.tcp://sparkExecutor@cshadoop6.utdallas.edu:50524/user/Executor#-1472369983] with ID 6
15/10/17 18:42:49 INFO util.RackResolver: Resolved cshadoop6.utdallas.edu to /default-rack

scala> 15/10/17 18:42:49 INFO storage.BlockManagerMasterActor: Registering block manager cshadoop2.utdallas.edu:51052 with 1060.3 MB RAM, BlockManagerId(5, cshadoop2.utdallas.edu, 51052)
15/10/17 18:42:50 INFO storage.BlockManagerMasterActor: Registering block manager cshadoop6.utdallas.edu:58546 with 1060.3 MB RAM, BlockManagerId(6, cshadoop6.utdallas.edu, 58546)


scala> var dataFile = sc.textFile("/yelpdatafall/review/review.csv")
15/10/17 18:44:07 INFO storage.MemoryStore: ensureFreeSpace(217490) called with curMem=0, maxMem=278302556
15/10/17 18:44:07 INFO storage.MemoryStore: Block broadcast_0 stored as values in memory (estimated size 212.4 KB, free 265.2 MB)
15/10/17 18:44:07 INFO storage.MemoryStore: ensureFreeSpace(31976) called with curMem=217490, maxMem=278302556
15/10/17 18:44:07 INFO storage.MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 31.2 KB, free 265.2 MB)
15/10/17 18:44:07 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on cs6360.utdallas.edu:49171 (size: 31.2 KB, free: 265.4 MB)
15/10/17 18:44:07 INFO storage.BlockManagerMaster: Updated info of block broadcast_0_piece0
15/10/17 18:44:07 INFO spark.SparkContext: Created broadcast 0 from textFile at <console>:12
dataFile: org.apache.spark.rdd.RDD[String] = /yelpdatafall/review/review.csv MappedRDD[1] at textFile at <console>:12

scala> def functavg[T]( t: Iterable[T] )( implicit num: Numeric[T] ) = {
     |      num.toDouble( t.sum ) / t.size
     |      }
functavg: [T](t: Iterable[T])(implicit num: Numeric[T])Double

scala> var mapDatafile  = file.map(a => a.split("\\^")).map(lb => (lb(2),lb(3).toDouble)).groupByKey()
<console>:10: error: not found: value file
       var mapDatafile  = file.map(a => a.split("\\^")).map(lb => (lb(2),lb(3).toDouble)).groupByKey()
                          ^

scala> var mapDatafile  = dataFile.map(a => a.split("\\^")).map(lb => (lb(2),lb(3).toDouble)).groupByKey()
15/10/17 18:45:01 INFO mapred.FileInputFormat: Total input paths to process : 1
mapDatafile: org.apache.spark.rdd.RDD[(String, Iterable[Double])] = ShuffledRDD[4] at groupByKey at <console>:14

scala>

scala> val sort = mapDatafile.map(a => (a._1, functavg (a._2))).sortByKey()
15/10/17 18:45:12 INFO spark.SparkContext: Starting job: sortByKey at <console>:18
15/10/17 18:45:12 INFO scheduler.DAGScheduler: Registering RDD 3 (map at <console>:14)
15/10/17 18:45:12 INFO scheduler.DAGScheduler: Got job 0 (sortByKey at <console>:18) with 2 output partitions (allowLocal=false)
15/10/17 18:45:12 INFO scheduler.DAGScheduler: Final stage: Stage 1(sortByKey at <console>:18)
15/10/17 18:45:12 INFO scheduler.DAGScheduler: Parents of final stage: List(Stage 0)
15/10/17 18:45:12 INFO scheduler.DAGScheduler: Missing parents: List(Stage 0)
15/10/17 18:45:12 INFO scheduler.DAGScheduler: Submitting Stage 0 (MappedRDD[3] at map at <console>:14), which has no missing parents
15/10/17 18:45:12 INFO storage.MemoryStore: ensureFreeSpace(3568) called with curMem=249466, maxMem=278302556
15/10/17 18:45:12 INFO storage.MemoryStore: Block broadcast_1 stored as values in memory (estimated size 3.5 KB, free 265.2 MB)
15/10/17 18:45:12 INFO storage.MemoryStore: ensureFreeSpace(2521) called with curMem=253034, maxMem=278302556
15/10/17 18:45:12 INFO storage.MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.5 KB, free 265.2 MB)
15/10/17 18:45:12 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on cs6360.utdallas.edu:49171 (size: 2.5 KB, free: 265.4 MB)
15/10/17 18:45:12 INFO storage.BlockManagerMaster: Updated info of block broadcast_1_piece0
15/10/17 18:45:12 INFO spark.SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:838
15/10/17 18:45:12 INFO scheduler.DAGScheduler: Submitting 2 missing tasks from Stage 0 (MappedRDD[3] at map at <console>:14)
15/10/17 18:45:12 INFO cluster.YarnClientClusterScheduler: Adding task set 0.0 with 2 tasks
15/10/17 18:45:12 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, cshadoop8.utdallas.edu, NODE_LOCAL, 1300 bytes)
15/10/17 18:45:12 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, cshadoop8.utdallas.edu, NODE_LOCAL, 1300 bytes)
15/10/17 18:45:13 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on cshadoop8.utdallas.edu:58927 (size: 2.5 KB, free: 1060.3 MB)
15/10/17 18:45:13 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on cshadoop8.utdallas.edu:58927 (size: 31.2 KB, free: 1060.3 MB)
15/10/17 18:45:15 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 2292 ms on cshadoop8.utdallas.edu (1/2)
15/10/17 18:45:15 INFO scheduler.TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 2299 ms on cshadoop8.utdallas.edu (2/2)
15/10/17 18:45:15 INFO cluster.YarnClientClusterScheduler: Removed TaskSet 0.0, whose tasks have all completed, from pool
15/10/17 18:45:15 INFO scheduler.DAGScheduler: Stage 0 (map at <console>:14) finished in 2.328 s
15/10/17 18:45:15 INFO scheduler.DAGScheduler: looking for newly runnable stages
15/10/17 18:45:15 INFO scheduler.DAGScheduler: running: Set()
15/10/17 18:45:15 INFO scheduler.DAGScheduler: waiting: Set(Stage 1)
15/10/17 18:45:15 INFO scheduler.DAGScheduler: failed: Set()
15/10/17 18:45:15 INFO scheduler.DAGScheduler: Missing parents for Stage 1: List()
15/10/17 18:45:15 INFO scheduler.DAGScheduler: Submitting Stage 1 (MapPartitionsRDD[7] at sortByKey at <console>:18), which is now runnable
15/10/17 18:45:15 INFO storage.MemoryStore: ensureFreeSpace(6432) called with curMem=255555, maxMem=278302556
15/10/17 18:45:15 INFO storage.MemoryStore: Block broadcast_2 stored as values in memory (estimated size 6.3 KB, free 265.2 MB)
15/10/17 18:45:15 INFO storage.MemoryStore: ensureFreeSpace(4193) called with curMem=261987, maxMem=278302556
15/10/17 18:45:15 INFO storage.MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 4.1 KB, free 265.2 MB)
15/10/17 18:45:15 INFO storage.BlockManagerInfo: Added broadcast_2_piece0 in memory on cs6360.utdallas.edu:49171 (size: 4.1 KB, free: 265.4 MB)
15/10/17 18:45:15 INFO storage.BlockManagerMaster: Updated info of block broadcast_2_piece0
15/10/17 18:45:15 INFO spark.SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:838
15/10/17 18:45:15 INFO scheduler.DAGScheduler: Submitting 2 missing tasks from Stage 1 (MapPartitionsRDD[7] at sortByKey at <console>:18)
15/10/17 18:45:15 INFO cluster.YarnClientClusterScheduler: Adding task set 1.0 with 2 tasks
15/10/17 18:45:15 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, cshadoop2.utdallas.edu, PROCESS_LOCAL, 1056 bytes)
15/10/17 18:45:15 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, cshadoop8.utdallas.edu, PROCESS_LOCAL, 1056 bytes)
15/10/17 18:45:15 INFO storage.BlockManagerInfo: Added broadcast_2_piece0 in memory on cshadoop8.utdallas.edu:58927 (size: 4.1 KB, free: 1060.3 MB)
15/10/17 18:45:15 INFO spark.MapOutputTrackerMasterActor: Asked to send map output locations for shuffle 0 to sparkExecutor@cshadoop8.utdallas.edu:47316
15/10/17 18:45:15 INFO spark.MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 159 bytes
15/10/17 18:45:15 INFO storage.BlockManagerInfo: Added broadcast_2_piece0 in memory on cshadoop2.utdallas.edu:51052 (size: 4.1 KB, free: 1060.3 MB)
15/10/17 18:45:15 INFO spark.MapOutputTrackerMasterActor: Asked to send map output locations for shuffle 0 to sparkExecutor@cshadoop2.utdallas.edu:37446
15/10/17 18:45:16 INFO scheduler.TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 1253 ms on cshadoop8.utdallas.edu (1/2)
15/10/17 18:45:17 INFO scheduler.DAGScheduler: Stage 1 (sortByKey at <console>:18) finished in 2.039 s
15/10/17 18:45:17 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 2035 ms on cshadoop2.utdallas.edu (2/2)
15/10/17 18:45:17 INFO cluster.YarnClientClusterScheduler: Removed TaskSet 1.0, whose tasks have all completed, from pool
15/10/17 18:45:17 INFO scheduler.DAGScheduler: Job 0 finished: sortByKey at <console>:18, took 4.551015 s
sort: org.apache.spark.rdd.RDD[(String, Double)] = ShuffledRDD[8] at sortByKey at <console>:18

scala> val outputq2b =sort.map(a => (a._2, a._1)). top(10).foreach(println)
15/10/17 18:45:29 INFO spark.SparkContext: Starting job: top at <console>:20
15/10/17 18:45:29 INFO scheduler.DAGScheduler: Registering RDD 5 (map at <console>:18)
15/10/17 18:45:29 INFO scheduler.DAGScheduler: Got job 1 (top at <console>:20) with 2 output partitions (allowLocal=false)
15/10/17 18:45:29 INFO scheduler.DAGScheduler: Final stage: Stage 4(top at <console>:20)
15/10/17 18:45:29 INFO scheduler.DAGScheduler: Parents of final stage: List(Stage 3)
15/10/17 18:45:29 INFO scheduler.DAGScheduler: Missing parents: List(Stage 3)
15/10/17 18:45:29 INFO scheduler.DAGScheduler: Submitting Stage 3 (MappedRDD[5] at map at <console>:18), which has no missing parents
15/10/17 18:45:29 INFO storage.MemoryStore: ensureFreeSpace(6480) called with curMem=266180, maxMem=278302556
15/10/17 18:45:29 INFO storage.MemoryStore: Block broadcast_3 stored as values in memory (estimated size 6.3 KB, free 265.1 MB)
15/10/17 18:45:29 INFO storage.MemoryStore: ensureFreeSpace(4261) called with curMem=272660, maxMem=278302556
15/10/17 18:45:29 INFO storage.MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 4.2 KB, free 265.1 MB)
15/10/17 18:45:29 INFO storage.BlockManagerInfo: Added broadcast_3_piece0 in memory on cs6360.utdallas.edu:49171 (size: 4.2 KB, free: 265.4 MB)
15/10/17 18:45:29 INFO storage.BlockManagerMaster: Updated info of block broadcast_3_piece0
15/10/17 18:45:29 INFO spark.SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:838
15/10/17 18:45:29 INFO scheduler.DAGScheduler: Submitting 2 missing tasks from Stage 3 (MappedRDD[5] at map at <console>:18)
15/10/17 18:45:29 INFO cluster.YarnClientClusterScheduler: Adding task set 3.0 with 2 tasks
15/10/17 18:45:29 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 3.0 (TID 4, cshadoop8.utdallas.edu, PROCESS_LOCAL, 1045 bytes)
15/10/17 18:45:29 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 3.0 (TID 5, cshadoop4.utdallas.edu, PROCESS_LOCAL, 1045 bytes)
15/10/17 18:45:29 INFO storage.BlockManagerInfo: Added broadcast_3_piece0 in memory on cshadoop8.utdallas.edu:58927 (size: 4.2 KB, free: 1060.2 MB)
15/10/17 18:45:29 INFO storage.BlockManagerInfo: Added broadcast_3_piece0 in memory on cshadoop4.utdallas.edu:59635 (size: 4.2 KB, free: 1060.3 MB)
15/10/17 18:45:29 INFO spark.MapOutputTrackerMasterActor: Asked to send map output locations for shuffle 0 to sparkExecutor@cshadoop4.utdallas.edu:56054
15/10/17 18:45:30 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 3.0 (TID 4) in 950 ms on cshadoop8.utdallas.edu (1/2)
15/10/17 18:45:31 INFO scheduler.DAGScheduler: Stage 3 (map at <console>:18) finished in 1.898 s
15/10/17 18:45:31 INFO scheduler.TaskSetManager: Finished task 1.0 in stage 3.0 (TID 5) in 1895 ms on cshadoop4.utdallas.edu (2/2)
15/10/17 18:45:31 INFO scheduler.DAGScheduler: looking for newly runnable stages
15/10/17 18:45:31 INFO scheduler.DAGScheduler: running: Set()
15/10/17 18:45:31 INFO scheduler.DAGScheduler: waiting: Set(Stage 4)
15/10/17 18:45:31 INFO cluster.YarnClientClusterScheduler: Removed TaskSet 3.0, whose tasks have all completed, from pool
15/10/17 18:45:31 INFO scheduler.DAGScheduler: failed: Set()
15/10/17 18:45:31 INFO scheduler.DAGScheduler: Missing parents for Stage 4: List()
15/10/17 18:45:31 INFO scheduler.DAGScheduler: Submitting Stage 4 (MapPartitionsRDD[10] at top at <console>:20), which is now runnable
15/10/17 18:45:31 INFO storage.MemoryStore: ensureFreeSpace(3376) called with curMem=276921, maxMem=278302556
15/10/17 18:45:31 INFO storage.MemoryStore: Block broadcast_4 stored as values in memory (estimated size 3.3 KB, free 265.1 MB)
15/10/17 18:45:31 INFO storage.MemoryStore: ensureFreeSpace(2395) called with curMem=280297, maxMem=278302556
15/10/17 18:45:31 INFO storage.MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 2.3 KB, free 265.1 MB)
15/10/17 18:45:31 INFO storage.BlockManagerInfo: Added broadcast_4_piece0 in memory on cs6360.utdallas.edu:49171 (size: 2.3 KB, free: 265.4 MB)
15/10/17 18:45:31 INFO storage.BlockManagerMaster: Updated info of block broadcast_4_piece0
15/10/17 18:45:31 INFO spark.SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:838
15/10/17 18:45:31 INFO scheduler.DAGScheduler: Submitting 2 missing tasks from Stage 4 (MapPartitionsRDD[10] at top at <console>:20)
15/10/17 18:45:31 INFO cluster.YarnClientClusterScheduler: Adding task set 4.0 with 2 tasks
15/10/17 18:45:31 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 4.0 (TID 6, cshadoop2.utdallas.edu, PROCESS_LOCAL, 1056 bytes)
15/10/17 18:45:31 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 4.0 (TID 7, cshadoop5.utdallas.edu, PROCESS_LOCAL, 1056 bytes)
15/10/17 18:45:31 INFO storage.BlockManager: Removing broadcast 3
15/10/17 18:45:31 INFO storage.BlockManagerInfo: Added broadcast_4_piece0 in memory on cshadoop2.utdallas.edu:51052 (size: 2.3 KB, free: 1060.3 MB)
15/10/17 18:45:31 INFO storage.BlockManager: Removing block broadcast_3_piece0
15/10/17 18:45:31 INFO storage.MemoryStore: Block broadcast_3_piece0 of size 4261 dropped from memory (free 278024125)
15/10/17 18:45:31 INFO storage.BlockManagerInfo: Removed broadcast_3_piece0 on cs6360.utdallas.edu:49171 in memory (size: 4.2 KB, free: 265.4 MB)
15/10/17 18:45:31 INFO storage.BlockManagerMaster: Updated info of block broadcast_3_piece0
15/10/17 18:45:31 INFO storage.BlockManager: Removing block broadcast_3
15/10/17 18:45:31 INFO storage.MemoryStore: Block broadcast_3 of size 6480 dropped from memory (free 278030605)
15/10/17 18:45:31 INFO storage.BlockManagerInfo: Removed broadcast_3_piece0 on cshadoop8.utdallas.edu:58927 in memory (size: 4.2 KB, free: 1060.3 MB)
15/10/17 18:45:31 INFO storage.BlockManagerInfo: Removed broadcast_3_piece0 on cshadoop4.utdallas.edu:59635 in memory (size: 4.2 KB, free: 1060.3 MB)
15/10/17 18:45:31 INFO spark.ContextCleaner: Cleaned broadcast 3
15/10/17 18:45:31 INFO storage.BlockManager: Removing broadcast 2
15/10/17 18:45:31 INFO storage.BlockManager: Removing block broadcast_2
15/10/17 18:45:31 INFO storage.MemoryStore: Block broadcast_2 of size 6432 dropped from memory (free 278037037)
15/10/17 18:45:31 INFO storage.BlockManager: Removing block broadcast_2_piece0
15/10/17 18:45:31 INFO storage.MemoryStore: Block broadcast_2_piece0 of size 4193 dropped from memory (free 278041230)
15/10/17 18:45:31 INFO storage.BlockManagerInfo: Removed broadcast_2_piece0 on cs6360.utdallas.edu:49171 in memory (size: 4.1 KB, free: 265.4 MB)
15/10/17 18:45:31 INFO storage.BlockManagerMaster: Updated info of block broadcast_2_piece0
15/10/17 18:45:31 INFO storage.BlockManagerInfo: Removed broadcast_2_piece0 on cshadoop8.utdallas.edu:58927 in memory (size: 4.1 KB, free: 1060.3 MB)
15/10/17 18:45:31 INFO storage.BlockManagerInfo: Removed broadcast_2_piece0 on cshadoop2.utdallas.edu:51052 in memory (size: 4.1 KB, free: 1060.3 MB)
15/10/17 18:45:31 INFO spark.MapOutputTrackerMasterActor: Asked to send map output locations for shuffle 1 to sparkExecutor@cshadoop2.utdallas.edu:37446
15/10/17 18:45:31 INFO spark.MapOutputTrackerMaster: Size of output statuses for shuffle 1 is 169 bytes
15/10/17 18:45:31 INFO spark.ContextCleaner: Cleaned broadcast 2
15/10/17 18:45:31 INFO storage.BlockManagerInfo: Added broadcast_4_piece0 in memory on cshadoop5.utdallas.edu:54305 (size: 2.3 KB, free: 1060.3 MB)
15/10/17 18:45:32 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 4.0 (TID 6) in 722 ms on cshadoop2.utdallas.edu (1/2)
15/10/17 18:45:32 INFO spark.MapOutputTrackerMasterActor: Asked to send map output locations for shuffle 1 to sparkExecutor@cshadoop5.utdallas.edu:55451
15/10/17 18:45:33 INFO scheduler.TaskSetManager: Finished task 1.0 in stage 4.0 (TID 7) in 2345 ms on cshadoop5.utdallas.edu (2/2)
15/10/17 18:45:33 INFO scheduler.DAGScheduler: Stage 4 (top at <console>:20) finished in 2.351 s
15/10/17 18:45:33 INFO cluster.YarnClientClusterScheduler: Removed TaskSet 4.0, whose tasks have all completed, from pool
15/10/17 18:45:33 INFO scheduler.DAGScheduler: Job 1 finished: top at <console>:20, took 4.333042 s
(5.0,zx1lLUvlRUN5nQlSj3HRDw)
(5.0,zweAzZDJ8SfwUID1UEGkbA)
(5.0,zvo21oKr656PQNVblYxYlg)
(5.0,ztswDToyZGyL_dxo0CEQew)
(5.0,zrmO-d-Mw3kv9dWa7Trr9Q)
(5.0,zqZjrcTf9Bc7r_VLGN4mrw)
(5.0,zkD9AtBT9ZkLFiV31gvEGw)
(5.0,ziS_fZ7Z99fa4qNVr879vg)
(5.0,zh2Eja5h54vM7GUibHoi9A)
(5.0,zh-MNFY4TyG7x2itUVlESQ)
outputq2b: Unit = ()

scala>
